{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1211a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import zstandard as zstd\n",
    "import time\n",
    "import csv\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d4377bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "secure = dict([e.split('=') for e in open('secure.txt', 'r').read().split('\\n')])\n",
    "# secure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b567dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_row_dir = 'tempo_rows.txt'\n",
    "rows = [line.strip() for line in open(tempo_row_dir, 'r') if line.strip()]\n",
    "download_dir = '/tmp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b256e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import os, csv\n",
    "\n",
    "# Extracts variables from the NetCDF file and writes it into a CSV file \n",
    "def extract_var_and_wr_csv(file_dir, output_csv_path, original_row):\n",
    "    \"\"\"\n",
    "    Process NetCDF files in a given directory to extract metadata and write to a CSV file, \n",
    "    including the original download URL and selected TEMPO variables.\n",
    "    \"\"\"\n",
    "    # List all NetCDF files in the specified directory\n",
    "    files = [f for f in os.listdir(file_dir) if f.endswith('.nc')]\n",
    "\n",
    "    # Headers: metadata + science variables\n",
    "    headers = [\n",
    "        'granule_id',\n",
    "        'original_row',\n",
    "        'time_start',\n",
    "        'time_end',\n",
    "        'product',\n",
    "        'location',\n",
    "        'split',\n",
    "        'granuleSize',\n",
    "        'vertical_column_troposphere',\n",
    "        'eff_cloud_fraction',\n",
    "        'solar_zenith_angle',\n",
    "        'viewing_zenith_angle',\n",
    "        'surface_pressure',\n",
    "        'terrain_height',\n",
    "        'main_data_quality_flag',\n",
    "        'ground_pixel_quality_flag',\n",
    "        'fit_rms_residual',\n",
    "        'amf_troposphere'\n",
    "    ]\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)\n",
    "\n",
    "    def find_var(nc, name):\n",
    "        \"\"\"Search root and all subgroups for a variable with this name.\"\"\"\n",
    "        if name in nc.variables:\n",
    "            return nc.variables[name]\n",
    "        for g in nc.groups.values():\n",
    "            if name in g.variables:\n",
    "                return g.variables[name]\n",
    "            # one more level deep just in case\n",
    "            for sg in g.groups.values():\n",
    "                if name in sg.variables:\n",
    "                    return sg.variables[name]\n",
    "        return None\n",
    "\n",
    "    def get_scalar(nc, name):\n",
    "        \"\"\"Return a single representative value (first finite element) for a variable.\"\"\"\n",
    "        var = find_var(nc, name)\n",
    "        if var is None:\n",
    "            return ''\n",
    "        data = var[:].flatten()\n",
    "        # Handle masked arrays\n",
    "        try:\n",
    "            data = data.compressed()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        for v in data:\n",
    "            # skip fill/NaN-like values\n",
    "            try:\n",
    "                if v is not None and v == v:  # v == v filters out NaN\n",
    "                    return float(v)\n",
    "            except Exception:\n",
    "                continue\n",
    "        return ''\n",
    "\n",
    "    file_exists = os.path.exists(output_csv_path)\n",
    "    with open(output_csv_path, 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.DictWriter(csvfile, fieldnames=headers)\n",
    "\n",
    "        if not file_exists or os.stat(output_csv_path).st_size == 0:\n",
    "            csvwriter.writeheader()  # Write header only if file is empty\n",
    "\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(file_dir, file_name)\n",
    "            with Dataset(file_path, 'r') as nc:\n",
    "                # Metadata\n",
    "                timeStart = getattr(nc, 'time_coverage_start', 'NA')\n",
    "                timeEnd   = getattr(nc, 'time_coverage_end', 'NA')\n",
    "                product   = 'tempo'\n",
    "                location  = 'la'\n",
    "                split     = 'train'\n",
    "                granuleSize = os.path.getsize(file_path)\n",
    "\n",
    "                # Science variables (one scalar per granule)\n",
    "                vct = get_scalar(nc, 'vertical_column_troposphere')\n",
    "                ecf = get_scalar(nc, 'eff_cloud_fraction')\n",
    "                sza = get_scalar(nc, 'solar_zenith_angle')\n",
    "                vza = get_scalar(nc, 'viewing_zenith_angle')\n",
    "                sp  = get_scalar(nc, 'surface_pressure')\n",
    "                th  = get_scalar(nc, 'terrain_height')\n",
    "                mqf = get_scalar(nc, 'main_data_quality_flag')\n",
    "                gqf = get_scalar(nc, 'ground_pixel_quality_flag')\n",
    "                rms = get_scalar(nc, 'fit_rms_residual')\n",
    "                amf = get_scalar(nc, 'amf_troposphere')\n",
    "\n",
    "                csvwriter.writerow({\n",
    "                    'granule_id': file_name,\n",
    "                    'original_row': original_row,\n",
    "                    'time_start': timeStart,\n",
    "                    'time_end': timeEnd,\n",
    "                    'product': product,\n",
    "                    'location': location,\n",
    "                    'split': split,\n",
    "                    'granuleSize': granuleSize,\n",
    "                    'vertical_column_troposphere': vct,\n",
    "                    'eff_cloud_fraction': ecf,\n",
    "                    'solar_zenith_angle': sza,\n",
    "                    'viewing_zenith_angle': vza,\n",
    "                    'surface_pressure': sp,\n",
    "                    'terrain_height': th,\n",
    "                    'main_data_quality_flag': mqf,\n",
    "                    'ground_pixel_quality_flag': gqf,\n",
    "                    'fit_rms_residual': rms,\n",
    "                    'amf_troposphere': amf\n",
    "                })\n",
    "            print(f\"Successfully Written: {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2eed936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes the netcdf files in tmp to save storage space\n",
    "def os_remove():\n",
    "    tmp_dir = '/tmp/'  # The directory from which you want to delete files\n",
    "    files = [f for f in os.listdir(tmp_dir) if f.endswith('.nc')]  # List of all .nc files in the directory\n",
    "    \n",
    "    for filename in files:\n",
    "        file_path = os.path.join(tmp_dir, filename)  # Full path to the file\n",
    "        try:\n",
    "            os.remove(file_path)  # Delete the file\n",
    "            print(f\"Successfuly Deleted: {filename} from {tmp_dir}\")\n",
    "        except FileNotFoundError:  # Catch the specific exception if the file does not exist\n",
    "            print(f\"{filename} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0198c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFileS3(rows):\n",
    "    for i in range(1):\n",
    "        try:\n",
    "            values = {'email' : secure['username'], 'passwd' : secure['password'], 'action' : 'login'}\n",
    "            login_row = 'https://urs.earthdata.nasa.gov'\n",
    "            ret = requests.post(login_row, data=values)\n",
    "            if ret.status_code == 200:\n",
    "                print(\"Login successful.\")\n",
    "            else:\n",
    "                print(\"Bad Authentication\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(i)\n",
    "        \n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "    for row in rows:\n",
    "        try:\n",
    "            outfile = os.path.basename(row)\n",
    "            print(\"Downloading\", outfile)\n",
    "            with requests.get(row, cookies = ret.cookies, \n",
    "                              allow_redirects = True, stream=True) as r:\n",
    "                r.raise_for_status()\n",
    "                outfile_path = os.path.join(download_dir, outfile)\n",
    "                with open(outfile_path, 'wb') as f:\n",
    "                    for chunk in r.iter_content(chunk_size=1024*1024): \n",
    "                        f.write(chunk)\n",
    "                  \n",
    "            filename = row.split('/')[-1]\n",
    "            save_path = os.path.join(download_dir, filename)\n",
    "            print(f\"Downloaded and compressed {filename} to {save_path}\")\n",
    "            print(\"Extracting variables and writing to CSV.\")\n",
    "            extract_var_and_wr_csv('C:/tmp/', 'C:/csv/output.csv', row)\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error downloading {row}: {e}\")\n",
    "        finally:\n",
    "            print(\"Deleting: TEMPO File\")\n",
    "            os_remove()\n",
    "        \n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0a84032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful.\n",
      "Downloading TEMPO_NO2_L2_V03_20250916T214329Z_S012G07.nc\n",
      "Downloaded and compressed TEMPO_NO2_L2_V03_20250916T214329Z_S012G07.nc to /tmp/TEMPO_NO2_L2_V03_20250916T214329Z_S012G07.nc\n",
      "Extracting variables and writing to CSV.\n",
      "Successfully Written: TEMPO_NO2_L2_V03_20250916T214329Z_S012G07.nc\n",
      "Deleting: TEMPO File\n",
      "Successfuly Deleted: TEMPO_NO2_L2_V03_20250916T214329Z_S012G07.nc from /tmp/\n",
      "Downloading TEMPO_NO2_L2_V03_20250916T213646Z_S012G06.nc\n",
      "Deleting: TEMPO File\n",
      "Successfuly Deleted: TEMPO_NO2_L2_V03_20250916T213646Z_S012G06.nc from /tmp/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mloadFileS3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[33], line 26\u001b[0m, in \u001b[0;36mloadFileS3\u001b[1;34m(rows)\u001b[0m\n\u001b[0;32m     24\u001b[0m     outfile_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_dir, outfile)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(outfile_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 26\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1024\u001b[39m): \n\u001b[0;32m     27\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[0;32m     29\u001b[0m filename \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mattl\\miniforge3\\envs\\airchem\\lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\mattl\\miniforge3\\envs\\airchem\\lib\\site-packages\\urllib3\\response.py:1091\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1090\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1091\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1093\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m   1094\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\mattl\\miniforge3\\envs\\airchem\\lib\\site-packages\\urllib3\\response.py:980\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[1;32m--> 980\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\mattl\\miniforge3\\envs\\airchem\\lib\\site-packages\\urllib3\\response.py:904\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    901\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    914\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\mattl\\miniforge3\\envs\\airchem\\lib\\site-packages\\urllib3\\response.py:887\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\mattl\\miniforge3\\envs\\airchem\\lib\\http\\client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\mattl\\miniforge3\\envs\\airchem\\lib\\socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mattl\\miniforge3\\envs\\airchem\\lib\\ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\mattl\\miniforge3\\envs\\airchem\\lib\\ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loadFileS3(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d7794b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airchem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
